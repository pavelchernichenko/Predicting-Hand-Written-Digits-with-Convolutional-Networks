{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 5",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2j_maCcZ_Wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f419241f-9233-4048-e78b-f68e89910863"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.core import Dense, Flatten, Dropout, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "np.set_printoptions(precision=5, suppress=True)\n",
        "nb_classes = 10\n",
        "\n",
        "#image dimensions\n",
        "img_x, img_y = 28, 28\n",
        "\n",
        "#load the mnist data-set\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape the data into a 4D tension - (sample numher, x_img_size, y_img_size, num_channles)\n",
        "# because the MNIST is greyscale, we only have a single channel - RGB colour images would have 3\n",
        "X_train = X_train.reshape(X_train.shape[0], img_x, img_y, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_x, img_y, 1)\n",
        "input_shape = (img_x, img_y, 1)\n",
        "\n",
        "# convert the data to the right type\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print('x_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices - this is for use in the\n",
        "# categorical_crossentropy loss below\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H09XpHonkFPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1012
        },
        "outputId": "50836279-2844-470a-c403-bedd33abcbaf"
      },
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "convout1 = Conv2D(32, (3,3), strides=(1,1), padding='same', input_shape=input_shape, activation='relu')\n",
        "model1.add(convout1)\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "model1.add(Dense(nb_classes))\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adadelta',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "import os\n",
        "import h5py\n",
        "WEIGHTS_FNAME = 'mnist_cnn_weights_v1.hdf'\n",
        "if False and os.path.exists(WEIGHTS_FNAME):\n",
        "    # Just change the True to false to force re-training\n",
        "    print('Loading the existing weights')\n",
        "    model1.load_weights(WEIGHTS_FNAME)\n",
        "else:\n",
        "    batch_size = 128\n",
        "    nb_epoch = 10\n",
        "    model1.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
        "              verbose=1, validation_data=(X_test, Y_test))\n",
        "    model1.save_weights(WEIGHTS_FNAME, overwrite=True)\n",
        "\n",
        "score = model1.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test Score: ', score[0])\n",
        "print('Test Accuracy: ', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 804,554\n",
            "Trainable params: 804,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 52s 863us/step - loss: 0.3761 - acc: 0.8857 - val_loss: 0.1130 - val_acc: 0.9653\n",
            "Epoch 2/10\n",
            "26240/60000 [============>.................] - ETA: 27s - loss: 0.1633 - acc: 0.9530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-51912b8bdaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     model1.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n\u001b[0;32m---> 31\u001b[0;31m               verbose=1, validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_FNAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww_TF4mrkOvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show resulting confusion matrix\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "print(model1.predict(X_test[1:5]))\n",
        "print(Y_test[1:5])\n",
        "\n",
        "Y_pred = model1.predict(X_test)\n",
        "#Convert one-hot to index\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfefznNIkSQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example of a mistaken number using np.where\n",
        "mis_idx = np.where(y_test != y_pred)[0]\n",
        "print(mis_idx)\n",
        "print(mis_idx.shape)\n",
        "print(list(zip(y_test[mis_idx], y_pred[mis_idx])))\n",
        "\n",
        "#Visualize a convolved image\n",
        "from keras import backend as K\n",
        "\n",
        "inputs = [K.learning_phase()] + model1.inputs\n",
        "\n",
        "_convout1_f = K.function(inputs, [convout1.output])\n",
        "def convout1_f(X):\n",
        "    # the [0] is to disable the training phase flag\n",
        "    return _convout1_f([0] + [X])\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "def nice_imshow(ax, data, vmin=None, vmax=None, cmap=None):\n",
        "    #Wrapper around p1.imshow\n",
        "    if cmap is None:\n",
        "        cmap = cm.jet\n",
        "    if vmin is None:\n",
        "        vmin = data.min()\n",
        "    if vmax is None:\n",
        "        vmax = data.max()\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    im = ax.imshow(data, vmin=vmin, vmax=vmax, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    \n",
        "i = mis_idx[0]\n",
        "\n",
        "#show the first layer of convolutions on an input image\n",
        "X = X_test[i:i+1]\n",
        "print(X.shape)\n",
        "print(\"target: {}\".format(y_test[i]))\n",
        "print(\"predicted: {}\".format(y_pred[i]))\n",
        "X.reshape(28, 28)\n",
        "plt.figure()\n",
        "plt.title('input')\n",
        "nice_imshow(plt.gca(), np.squeeze(X), vmin=0, vmax=1, cmap=cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKoXd6mkXsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy.ma as ma\n",
        "def make_mosaic(imgs, nrows, ncols, border=1):\n",
        "    \n",
        "   #make a mosaic with n-rows and n-columns given set of images\n",
        "    \n",
        "    nimgs = imgs.shape[2]\n",
        "    print(nimgs)\n",
        "    imshape = imgs.shape[:2]\n",
        "    print(imshape)\n",
        "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
        "                           ncols * imshape[1] + (ncols - 1) * border),\n",
        "                          dtype=np.float32)\n",
        "    \n",
        "    paddedh = imshape[0] + border\n",
        "    paddedw = imshape[1] + border\n",
        "    for i in range(nimgs):\n",
        "        row = int(np.floor(i / ncols))\n",
        "        col = i % ncols\n",
        "        \n",
        "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
        "              col * paddedw:col * paddedw + imshape[1]] = imgs[:, :, i]\n",
        "    return mosaic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RijAi80kkbMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show weights\n",
        "print(len(model1.layers))\n",
        "print(type(model1.layers[0]))\n",
        "W = model1.layers[0].get_weights()[0]\n",
        "W = np.squeeze(W)\n",
        "print(\"W shape : \", W.shape)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.title('conv1 weights')\n",
        "nice_imshow(plt.gca(), make_mosaic(W, 6, 6), cmap=cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jQmAo3Zkd6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show convolution result\n",
        "#after activation\n",
        "C1 = convout1_f(X)\n",
        "C1 = np.squeeze(C1)\n",
        "print(\"C1 shape : \", C1.shape)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.suptitle('convout1')\n",
        "nice_imshow(plt.gca(), make_mosaic(C1, 6, 6), cmap=cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GCCIiAukhXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "outputId": "5111b0b2-2e77-4452-d1aa-39832a6a844b"
      },
      "source": [
        "#initializing the 2nd convolutional layer to use alongside \n",
        "#the 1st convolutional layer, which we are recycling from model1\n",
        "# kernel at 2x2 for better results/accuracy tests\n",
        "convout2 = Conv2D(32, (2,2), strides=(1,1), padding='same', activation='relu')\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(convout1)\n",
        "model2.add(convout2)\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Dense(nb_classes))\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adadelta',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model2.summary() \n",
        "\n",
        "WEIGHTS_FNAME2 = 'mnist_cnn_weights_v2.hdf'\n",
        "if False and os.path.exists(WEIGHTS_FNAME2):\n",
        "    # Just change the True to false to force re-training\n",
        "    print('Loading the existing weights')\n",
        "    model2.load_weights(WEIGHTS_FNAME2)\n",
        "else:\n",
        "    batch_size = 128\n",
        "    nb_epoch = 10\n",
        "    model2.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
        "              verbose=1, validation_data=(X_test, Y_test))\n",
        "    model2.save_weights(WEIGHTS_FNAME2, overwrite=True)\n",
        "\n",
        "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test Score: ', score[0])\n",
        "print('Test Accuracy: ', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 808,682\n",
            "Trainable params: 808,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " 8960/60000 [===>..........................] - ETA: 1:51 - loss: 0.6299 - acc: 0.8057"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e964e1c27b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     model2.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n\u001b[0;32m---> 31\u001b[0;31m               verbose=1, validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_FNAME2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gm4fXz_kkpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Time to view the resulting confusion matrix\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "print(model2.predict(X_test[1:5]))\n",
        "print(Y_test[1:5])\n",
        "\n",
        "Y_pred = model2.predict(X_test)\n",
        "#Convert one-hot to index\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX8tKQXSkoho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example of a mistaken number using np.where\n",
        "mis_idx = np.where(y_test != y_pred)[0]\n",
        "print(mis_idx)\n",
        "print(mis_idx.shape)\n",
        "print(list(zip(y_test[mis_idx], y_pred[mis_idx])))\n",
        "\n",
        "#Visualize a convolved image\n",
        "inputs = [K.learning_phase()] + model2.inputs\n",
        "\n",
        "_convout2_f = K.function(inputs, [convout2.output])\n",
        "def convout2_f(X):\n",
        "    #the [0] is to disable the training phase flag\n",
        "    return _convout2_f([0] + [X])\n",
        "    \n",
        "i = mis_idx[0]\n",
        "\n",
        "#show first layer of convolutions on an input image\n",
        "X = X_test[i:i+1]\n",
        "print(X.shape)\n",
        "print(\"target: {}\".format(y_test[i]))\n",
        "print(\"predicted: {}\".format(y_pred[i]))\n",
        "X.reshape(28, 28)\n",
        "plt.figure()\n",
        "plt.title('input')\n",
        "nice_imshow(plt.gca(), np.squeeze(X), vmin=0, vmax=1, cmap=cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N8BnyO_kwgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(model2.layers))\n",
        "print(type(model2.layers[0]))\n",
        "W = model2.layers[0].get_weights()[0]\n",
        "W = np.squeeze(W)\n",
        "print(\"W shape : \", W.shape)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.title('conv2 weights')\n",
        "nice_imshow(plt.gca(), make_mosaic(W, 6, 6), cmap=cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE-O3QYOk2vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show convolution result \n",
        "#after activation\n",
        "C1 = convout2_f(X)\n",
        "C1 = np.squeeze(C1)\n",
        "print(\"C1 shape : \", C1.shape)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.suptitle('convout2')\n",
        "nice_imshow(plt.gca(), make_mosaic(C1, 6, 6), cmap=cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd45660QgktF",
        "colab_type": "text"
      },
      "source": [
        "Questions :\n",
        "\n",
        "\n",
        "How many hidden layers are in your network? \n",
        "\n",
        "In my second  model I included  2 Convolutional layers, 1 hidden layer, one fully connected layer and one flattening layer. 5 total hidden layers.\n",
        "\n",
        "How many convolutions are calculated in each convolution layer?\n",
        "\n",
        "In my convolutional neural network I use padding. I use padding because when we take our 3 by 3 kernel for our first model snd with 9 total pixels, if the center of our kernel(center pixel) is close enough to the edge then that means that part of our kernel will hang off of the picture. By specifying the padding the padding allows us to let our kernel hang off the edge by only one space in a certain direction and one space in the other direction. If each image is 28 by 28 then the total number of pixels comes to 784. In order to account for the extra row we will need  1 by 1 padding on all sides. We will multiply the length of a row of pixels by 4 and then add 4. We will add 4 for the 4 off-grid pixels in the corner. The result area will be  784 + 4 + 28 * 4. Result of 900 total. Our convolutions can hang off of the edge by 1 pixel and our strides are 1x1, a centered convolution will occur in all 84 spaces within the 28 by 28 image. 784 convolutions will be calculated in each layer.\n",
        "\n",
        "Run a single test example through the model and print some of the convolved images from the first layer. Can you see any features from the image that are revealed by printing? \n",
        "\n",
        "Yes, the printed images have various shades of the number that we try to predicted. I noticed that the shades of the number vary on the spectrum from the inner portion of the number to the outer edges. We also notice that with this, some parts of the image are more focused on than others.\n",
        "\n",
        "Print a couple of the convolution kernels as matrices (no need to print images). What kind of patterns can you see in the convolution kernels? \n",
        "\n",
        "The convolution kernels seem to perform the same way, except the kernel demensions are different from model 1 and 2. when i ran model 2 with 2x2 instead of 3x3 i seemed to get better results/accuracy. The matrices seem to be the same general pattern with a few numbers that different in outlining areas. "
      ]
    }
  ]
}